{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5 Activity 2: \n",
    "# <span style=color:blue>Read tabular data from a PDF report of World Bank for doing some analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "* **Don't forget that a special package to load for this exercise is Tabula. You will need the `read_pdf` function from Tabula**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get familiar with the PDF file to be read\n",
    "#### Open the accompanying PDF file \"WDI-2016\" and browse through it quickly. It is an annual report from World Bank on World Development Indicators (poverty, hunger, child mortality, social mobility, education, etc.)\n",
    "\n",
    "#### Go to pages 68-72 to look at the tables we need toextract in this activity for analysis. They show various statistics for nations around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a list of page numbers to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of column names. This will not be extracted by the PDF reader correctly, so we need to manually use it later.\n",
    "\n",
    "#### Look at the pages 68-72 and come up with these variable names. Use your own judgment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a PDF table extraction by using the `read_pdf` function from Tabula\n",
    "\n",
    "* **You can read details on this library here: https://github.com/chezou/tabula-py**\n",
    "* **You may have to set `multiple_tables=True` in this case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have done previous step correctly, you should get a simple list back. Check its length and contents. Do you see the table (as a Pandas DataFrame) in the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to check the length of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to check the first element of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to check the second element of the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like that the 2nd element of the list is the table we want to extract. Let's assign it to a DataFrame and check first few rows using `head` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should observe that the column headers are just numbers. Here, we need to use the defined list of variables we created earlier. Assign that list as column names of this DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, write a loop to create such DataFrames by reading data tables from the pages 68-72 of the PDF file. You can store those DataFrames in a list for concatenating later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine individual DataFrames from the list. Does the last DataFrame look alright?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concetenate all the DataFrames in the list into a single DataFrame so that we can use it for further wrangling and analysis.\n",
    "\n",
    "* Check the shape of the DataFrame. It should show 226 entries in total with 11 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to concatenate the individual DataFrames into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here to examine the final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the Data set clean and ready to be analyzed? \n",
    "* **Are there missing entries? How to handle them?**\n",
    "* **Are there entries not specific to countries but regions? Do we need them here or can they be copied to another data set?**\n",
    "\n",
    "#### As with any real-world example, this data set also needs further wrangling and cleaning before it can be used in an analytics pipeline. But you have already mastered many of those data cleaning techniques from the previous lessons! So those will not be discussed here but you can try on your own how to extract beautiful plots and insights from this dataset by using your data wrangling skills!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
